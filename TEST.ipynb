{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime, os, sys\n",
    "import pickle as pkl\n",
    "from subprocess import call, Popen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\APP_Home\\Anaconda\\envs\\brats_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\APP_Home\\Anaconda\\envs\\brats_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\APP_Home\\Anaconda\\envs\\brats_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\APP_Home\\Anaconda\\envs\\brats_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\APP_Home\\Anaconda\\envs\\brats_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\APP_Home\\Anaconda\\envs\\brats_tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music_data_utils\n",
    "from midi_statistics import get_all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.flags\n",
    "logging = tf.logging\n",
    "\n",
    "flags.DEFINE_string(\"datadir\", None, \"Directory to save and load midi music files.\")\n",
    "flags.DEFINE_string(\"traindir\", None, \"Directory to save checkpoints and gnuplot files.\")\n",
    "flags.DEFINE_integer(\"epochs_per_checkpoint\", 2,\n",
    "                     \"How many training epochs to do per checkpoint.\")\n",
    "flags.DEFINE_boolean(\"log_device_placement\", False,           #\n",
    "                   \"Outputs info on device placement.\")\n",
    "flags.DEFINE_string(\"call_after\", None, \"Call this command after exit.\")\n",
    "flags.DEFINE_integer(\"exit_after\", 1440,\n",
    "                     \"exit after this many minutes\")\n",
    "flags.DEFINE_integer(\"select_validation_percentage\", None,\n",
    "                     \"Select random percentage of data as validation set.\")\n",
    "flags.DEFINE_integer(\"select_test_percentage\", None,\n",
    "                     \"Select random percentage of data as test set.\")\n",
    "flags.DEFINE_boolean(\"sample\", False,\n",
    "                     \"Sample output from the model. Assume training was already done. Save sample output to file.\")\n",
    "flags.DEFINE_integer(\"works_per_composer\", None,\n",
    "                     \"Limit number of works per composer that is loaded.\")\n",
    "flags.DEFINE_boolean(\"disable_feed_previous\", False,\n",
    "                     \"Feed output from previous cell to the input of the next. In the generator.\")\n",
    "flags.DEFINE_float(\"init_scale\", 0.05,                # .1, .04\n",
    "                   \"the initial scale of the weights\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.1,              # .05,.1,.9 \n",
    "                   \"Learning rate\")\n",
    "flags.DEFINE_float(\"d_lr_factor\", 0.5,                # .5\n",
    "                   \"Learning rate decay\")\n",
    "flags.DEFINE_float(\"max_grad_norm\", 5.0,              # 5.0, 10.0\n",
    "                   \"the maximum permissible norm of the gradient\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.5,                  # 1.0, .35\n",
    "                   \"Keep probability. 1.0 disables dropout.\")\n",
    "flags.DEFINE_float(\"lr_decay\", 1.0,                   # 1.0\n",
    "                   \"Learning rate decay after each epoch after epochs_before_decay\")\n",
    "flags.DEFINE_integer(\"num_layers_g\", 2,                 # 2\n",
    "                   \"Number of stacked recurrent cells in G.\")\n",
    "flags.DEFINE_integer(\"num_layers_d\", 2,                 # 2\n",
    "                   \"Number of stacked recurrent cells in D.\")\n",
    "flags.DEFINE_integer(\"songlength\", 100,               # 200, 500\n",
    "                   \"Limit song inputs to this number of events.\")\n",
    "flags.DEFINE_integer(\"meta_layer_size\", 200,          # 300, 600\n",
    "                   \"Size of hidden layer for meta information module.\")\n",
    "flags.DEFINE_integer(\"hidden_size_g\", 100,              # 200, 1500\n",
    "                   \"Hidden size for recurrent part of G.\")\n",
    "flags.DEFINE_integer(\"hidden_size_d\", 100,              # 200, 1500\n",
    "                   \"Hidden size for recurrent part of D. Default: same as for G.\")\n",
    "flags.DEFINE_integer(\"epochs_before_decay\", 60,       # 40, 140\n",
    "                   \"Number of epochs before starting to decay.\")\n",
    "flags.DEFINE_integer(\"max_epoch\", 500,                # 500, 500\n",
    "                   \"Number of epochs before stopping training.\")\n",
    "flags.DEFINE_integer(\"batch_size\", 20,                # 10, 20\n",
    "                   \"Batch size.\")\n",
    "flags.DEFINE_integer(\"biscale_slow_layer_ticks\", 8,   # 8\n",
    "                   \"Biscale slow layer ticks. Not implemented yet.\")\n",
    "flags.DEFINE_boolean(\"multiscale\", False,             #\n",
    "                   \"Multiscale RNN. Not implemented.\")\n",
    "flags.DEFINE_integer(\"pretraining_epochs\", 6,        # 20, 40\n",
    "                   \"Number of epochs to run lang-model style pretraining.\")\n",
    "flags.DEFINE_boolean(\"pretraining_d\", False,          #\n",
    "                   \"Train D during pretraining.\")\n",
    "flags.DEFINE_boolean(\"initialize_d\", False,           #\n",
    "                   \"Initialize variables for D, no matter if there are trained versions in checkpoint.\")\n",
    "flags.DEFINE_boolean(\"ignore_saved_args\", False,      #\n",
    "                   \"Tells the program to ignore saved arguments, and instead use the ones provided as CLI arguments.\")\n",
    "flags.DEFINE_boolean(\"pace_events\", False,            #\n",
    "                   \"When parsing input data, insert one dummy event at each quarter note if there is no tone.\")\n",
    "flags.DEFINE_boolean(\"minibatch_d\", False,            #\n",
    "                   \"Adding kernel features for minibatch diversity.\")\n",
    "flags.DEFINE_boolean(\"unidirectional_d\", False,        #\n",
    "                   \"Unidirectional RNN instead of bidirectional RNN for D.\")\n",
    "flags.DEFINE_boolean(\"profiling\", False,              #\n",
    "                   \"Profiling. Writing a timeline.json file in plots dir.\")\n",
    "flags.DEFINE_boolean(\"float16\", False,                #\n",
    "                   \"Use floa16 data type. Otherwise, use float32.\")\n",
    "\n",
    "flags.DEFINE_boolean(\"adam\", False,                   #\n",
    "                   \"Use Adam optimizer.\")\n",
    "flags.DEFINE_boolean(\"feature_matching\", False,       #\n",
    "                   \"Feature matching objective for G.\")\n",
    "flags.DEFINE_boolean(\"disable_l2_regularizer\", False,       #\n",
    "                   \"L2 regularization on weights.\")\n",
    "flags.DEFINE_float(\"reg_scale\", 1.0,       #\n",
    "                   \"L2 regularization scale.\")\n",
    "flags.DEFINE_boolean(\"synthetic_chords\", False,       #\n",
    "                   \"Train on synthetically generated chords (three tones per event).\")\n",
    "flags.DEFINE_integer(\"tones_per_cell\", 1,             # 2,3\n",
    "                   \"Maximum number of tones to output per RNN cell.\")\n",
    "flags.DEFINE_string(\"composer\", None, \"Specify exactly one composer, and train model only on this.\")\n",
    "flags.DEFINE_boolean(\"generate_meta\", False, \"Generate the composer and genre as part of output.\")\n",
    "flags.DEFINE_float(\"random_input_scale\", 1.0,       #\n",
    "                   \"Scale of random inputs (1.0=same size as generated features).\")\n",
    "flags.DEFINE_boolean(\"end_classification\", False, \"Classify only in ends of D. Otherwise, does classification at every timestep and mean reduce.\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "model_layout_flags = ['num_layers_g', 'num_layers_d', 'meta_layer_size', 'hidden_size_g', 'hidden_size_d', 'biscale_slow_layer_ticks', 'multiscale', 'multiscale', 'disable_feed_previous', 'pace_events', 'minibatch_d', 'unidirectional_d', 'feature_matching', 'composer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rnn_cell(rnn_layer_sizes,\n",
    "                  dropout_keep_prob=1.0,\n",
    "                  attn_length=0,\n",
    "                  base_cell=tf.contrib.rnn.BasicLSTMCell,\n",
    "                  state_is_tuple=True,\n",
    "                  reuse=False):\n",
    "  \"\"\"Makes a RNN cell from the given hyperparameters.\n",
    "\n",
    "  Args:\n",
    "    rnn_layer_sizes: A list of integer sizes (in units) for each layer of the RNN.\n",
    "    dropout_keep_prob: The float probability to keep the output of any given sub-cell.\n",
    "    attn_length: The size of the attention vector.\n",
    "    base_cell: The base tf.contrib.rnn.RNNCell to use for sub-cells.\n",
    "    state_is_tuple: A boolean specifying whether to use tuple of hidden matrix\n",
    "        and cell matrix as a state instead of a concatenated matrix.\n",
    "\n",
    "  Returns:\n",
    "      A tf.contrib.rnn.MultiRNNCell based on the given hyperparameters.\n",
    "  \"\"\"\n",
    "  cells = []\n",
    "  for num_units in rnn_layer_sizes:\n",
    "    cell = base_cell(num_units, state_is_tuple=state_is_tuple, reuse=reuse)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        cell, output_keep_prob=dropout_keep_prob)\n",
    "    cells.append(cell)\n",
    "\n",
    "  cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=state_is_tuple)\n",
    "  if attn_length:\n",
    "    cell = tf.contrib.rnn.AttentionCellWrapper(\n",
    "        cell, attn_length, state_is_tuple=state_is_tuple, reuse=reuse)\n",
    "\n",
    "  return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_flags(save_if_none_found=True):\n",
    "  if FLAGS.traindir:\n",
    "    saved_args_dir = os.path.join(FLAGS.traindir, 'saved_args')\n",
    "    if save_if_none_found:\n",
    "      try: os.makedirs(saved_args_dir)\n",
    "      except: pass\n",
    "    for arg in FLAGS.__flags:\n",
    "      if arg not in model_layout_flags:\n",
    "        continue\n",
    "      if FLAGS.ignore_saved_args and os.path.exists(os.path.join(saved_args_dir, arg+'.pkl')):\n",
    "        print('{:%Y-%m-%d %H:%M:%S}: saved_args: Found {} setting from saved state, but using CLI args ({}) and saving (--ignore_saved_args).'.format(datetime.datetime.today(), arg, getattr(FLAGS, arg)))\n",
    "      elif os.path.exists(os.path.join(saved_args_dir, arg+'.pkl')):\n",
    "        with open(os.path.join(saved_args_dir, arg+'.pkl'), 'rb') as f:\n",
    "          setattr(FLAGS, arg, pkl.load(f))\n",
    "          print('{:%Y-%m-%d %H:%M:%S}: saved_args: {} from saved state ({}), ignoring CLI args.'.format(datetime.datetime.today(), arg, getattr(FLAGS, arg)))\n",
    "      elif save_if_none_found:\n",
    "        print('{:%Y-%m-%d %H:%M:%S}: saved_args: Found no {} setting from saved state, using CLI args ({}) and saving.'.format(datetime.datetime.today(), arg, getattr(FLAGS, arg)))\n",
    "        with open(os.path.join(saved_args_dir, arg+'.pkl'), 'wb') as f:\n",
    "            print(getattr(FLAGS, arg),arg)\n",
    "            pkl.dump(getattr(FLAGS, arg), f)\n",
    "      else:\n",
    "        print('{:%Y-%m-%d %H:%M:%S}: saved_args: Found no {} setting from saved state, using CLI args ({}) but not saving.'.format(datetime.datetime.today(), arg, getattr(FLAGS, arg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type():\n",
    "  return tf.float16 if FLAGS.float16 else tf.float32\n",
    "  #return tf.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_reduce_mean(what_to_take_mean_over):\n",
    "  return tf.reshape(what_to_take_mean_over, shape=[-1])[0]\n",
    "  denom = 1.0\n",
    "  #print(what_to_take_mean_over.get_shape())\n",
    "  for d in what_to_take_mean_over.get_shape():\n",
    "    #print(d)\n",
    "    if type(d) == tf.Dimension:\n",
    "      denom = denom*d.value\n",
    "    else:\n",
    "      denom = denom*d\n",
    "  return tf.reduce_sum(what_to_take_mean_over)/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(inp, output_dim, scope=None, stddev=1.0, reuse_scope=False):\n",
    "  norm = tf.random_normal_initializer(stddev=stddev, dtype=data_type())\n",
    "  const = tf.constant_initializer(0.0, dtype=data_type())\n",
    "  with tf.variable_scope(scope or 'linear') as scope:\n",
    "    scope.set_regularizer(tf.contrib.layers.l2_regularizer(scale=FLAGS.reg_scale))\n",
    "    if reuse_scope:\n",
    "      scope.reuse_variables()\n",
    "    #print('inp.get_shape(): {}'.format(inp.get_shape()))\n",
    "    w = tf.get_variable('w', [inp.get_shape()[1], output_dim], initializer=norm, dtype=data_type())\n",
    "    b = tf.get_variable('b', [output_dim], initializer=const, dtype=data_type())\n",
    "  return tf.matmul(inp, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(inp, num_kernels=25, kernel_dim=10, scope=None, msg='', reuse_scope=False):\n",
    "  \"\"\"\n",
    "   Borrowed from http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope or 'minibatch_d') as scope:\n",
    "    scope.set_regularizer(tf.contrib.layers.l2_regularizer(scale=FLAGS.reg_scale))\n",
    "    if reuse_scope:\n",
    "      scope.reuse_variables()\n",
    "  \n",
    "    inp = tf.Print(inp, [inp],\n",
    "            '{} inp = '.format(msg), summarize=20, first_n=20)\n",
    "    x = tf.sigmoid(linear(inp, num_kernels * kernel_dim, scope))\n",
    "    activation = tf.reshape(x, (-1, num_kernels, kernel_dim))\n",
    "    activation = tf.Print(activation, [activation],\n",
    "            '{} activation = '.format(msg), summarize=20, first_n=20)\n",
    "    diffs = tf.expand_dims(activation, 3) - \\\n",
    "                tf.expand_dims(tf.transpose(activation, [1, 2, 0]), 0)\n",
    "    diffs = tf.Print(diffs, [diffs],\n",
    "            '{} diffs = '.format(msg), summarize=20, first_n=20)\n",
    "    abs_diffs = tf.reduce_sum(tf.abs(diffs), 2)\n",
    "    abs_diffs = tf.Print(abs_diffs, [abs_diffs],\n",
    "            '{} abs_diffs = '.format(msg), summarize=20, first_n=20)\n",
    "    minibatch_features = tf.reduce_sum(tf.exp(-abs_diffs), 2)\n",
    "    minibatch_features = tf.Print(minibatch_features, [tf.reduce_min(minibatch_features), tf.reduce_max(minibatch_features)],\n",
    "            '{} minibatch_features (min,max) = '.format(msg), summarize=20, first_n=20)\n",
    "  return tf.concat( [inp, minibatch_features],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNGAN(object):\n",
    "  \"\"\"The RNNGAN model.\"\"\"\n",
    "\n",
    "  def __init__(self, is_training, num_song_features=None, num_meta_features=None):\n",
    "    batch_size = FLAGS.batch_size\n",
    "    self.batch_size =  batch_size\n",
    "\t\n",
    "    songlength = FLAGS.songlength\n",
    "    self.songlength = songlength#self.global_step            = tf.Variable(0, trainable=False)\n",
    "\n",
    "    print('songlength: {}'.format(self.songlength))\n",
    "    self._input_songdata = tf.placeholder(shape=[batch_size, songlength, num_song_features], dtype=data_type())\n",
    "    self._input_metadata = tf.placeholder(shape=[batch_size, num_meta_features], dtype=data_type())\n",
    "    #_split = tf.split(self._input_songdata,songlength,1)[0]\n",
    "    print(\"self._input_songdata\",self._input_songdata, 'songlength',songlength)\n",
    "    #print(tf.squeeze(_split,[1]))\n",
    "    songdata_inputs = [tf.squeeze(input_, [1])\n",
    "              for input_ in tf.split(self._input_songdata,songlength,1)]\n",
    "  \n",
    "    \n",
    "    with tf.variable_scope('G') as scope:\n",
    "      scope.set_regularizer(tf.contrib.layers.l2_regularizer(scale=FLAGS.reg_scale))\n",
    "      #lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(FLAGS.hidden_size_g, forget_bias=1.0, state_is_tuple=True)\n",
    "      if is_training and FLAGS.keep_prob < 1:\n",
    "        #lstm_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "        #    lstm_cell, output_keep_prob=FLAGS.keep_prob)\n",
    "        cell = make_rnn_cell([FLAGS.hidden_size_g]*FLAGS.num_layers_g,dropout_keep_prob=FLAGS.keep_prob)\n",
    "      else:\n",
    "         cell = make_rnn_cell([FLAGS.hidden_size_g]*FLAGS.num_layers_g)\t  \n",
    "\n",
    "      #cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell for _ in range( FLAGS.num_layers_g)], state_is_tuple=True)\n",
    "      self._initial_state = cell.zero_state(batch_size, data_type())\n",
    "\n",
    "      # TODO: (possibly temporarily) disabling meta info\n",
    "      if FLAGS.generate_meta:\n",
    "        metainputs = tf.random_uniform(shape=[batch_size, int(FLAGS.random_input_scale*num_meta_features)], minval=0.0, maxval=1.0)\n",
    "        meta_g = tf.nn.relu(linear(metainputs, FLAGS.meta_layer_size, scope='meta_layer', reuse_scope=False))\n",
    "        meta_softmax_w = tf.get_variable(\"meta_softmax_w\", [FLAGS.meta_layer_size, num_meta_features])\n",
    "        meta_softmax_b = tf.get_variable(\"meta_softmax_b\", [num_meta_features])\n",
    "        meta_logits = tf.nn.xw_plus_b(meta_g, meta_softmax_w, meta_softmax_b)\n",
    "        meta_probs = tf.nn.softmax(meta_logits)\n",
    "\n",
    "      random_rnninputs = tf.random_uniform(shape=[batch_size, songlength, int(FLAGS.random_input_scale*num_song_features)], minval=0.0, maxval=1.0, dtype=data_type())\n",
    "\n",
    "      # Make list of tensors. One per step in recurrence.\n",
    "      # Each tensor is batchsize*numfeatures.\n",
    "      \n",
    "      random_rnninputs = [tf.squeeze(input_, [1]) for input_ in tf.split( random_rnninputs,songlength,1)]\n",
    "      \n",
    "      # REAL GENERATOR:\n",
    "      state = self._initial_state\n",
    "      # as we feed the output as the input to the next, we 'invent' the initial 'output'.\n",
    "      generated_point = tf.random_uniform(shape=[batch_size, num_song_features], minval=0.0, maxval=1.0, dtype=data_type())\n",
    "      outputs = []\n",
    "      self._generated_features = []\n",
    "      for i,input_ in enumerate(random_rnninputs):\n",
    "        if i > 0: scope.reuse_variables()\n",
    "        concat_values = [input_]\n",
    "        if not FLAGS.disable_feed_previous:\n",
    "          concat_values.append(generated_point)\n",
    "        if FLAGS.generate_meta:\n",
    "          concat_values.append(meta_probs)\n",
    "        if len(concat_values):\n",
    "          input_ = tf.concat(axis=1, values=concat_values)\n",
    "        input_ = tf.nn.relu(linear(input_, FLAGS.hidden_size_g,\n",
    "                            scope='input_layer', reuse_scope=(i!=0)))\n",
    "        output, state = cell(input_, state)\n",
    "        outputs.append(output)\n",
    "        #generated_point = tf.nn.relu(linear(output, num_song_features, scope='output_layer', reuse_scope=(i!=0)))\n",
    "        generated_point = linear(output, num_song_features, scope='output_layer', reuse_scope=(i!=0))\n",
    "        self._generated_features.append(generated_point)\n",
    "      \n",
    "      \n",
    "      # PRETRAINING GENERATOR, will feed inputs, not generated outputs:\n",
    "      scope.reuse_variables()\n",
    "      # as we feed the output as the input to the next, we 'invent' the initial 'output'.\n",
    "      prev_target = tf.random_uniform(shape=[batch_size, num_song_features], minval=0.0, maxval=1.0, dtype=data_type())\n",
    "      outputs = []\n",
    "      self._generated_features_pretraining = []\n",
    "      for i,input_ in enumerate(random_rnninputs):\n",
    "        concat_values = [input_]\n",
    "        if not FLAGS.disable_feed_previous:\n",
    "          concat_values.append(prev_target)\n",
    "        if FLAGS.generate_meta:\n",
    "          concat_values.append(self._input_metadata)\n",
    "        if len(concat_values):\n",
    "          input_ = tf.concat(axis=1, values=concat_values)\n",
    "        input_ = tf.nn.relu(linear(input_, FLAGS.hidden_size_g, scope='input_layer', reuse_scope=(i!=0)))\n",
    "        output, state = cell(input_, state)\n",
    "        outputs.append(output)\n",
    "        #generated_point = tf.nn.relu(linear(output, num_song_features, scope='output_layer', reuse_scope=(i!=0)))\n",
    "        generated_point = linear(output, num_song_features, scope='output_layer', reuse_scope=(i!=0))\n",
    "        self._generated_features_pretraining.append(generated_point)\n",
    "        prev_target = songdata_inputs[i]\n",
    "      \n",
    "      #outputs, state = tf.nn.rnn(cell, transformed, initial_state=self._initial_state)\n",
    "\n",
    "      #self._generated_features = [tf.nn.relu(linear(output, num_song_features, scope='output_layer', reuse_scope=(i!=0))) for i,output in enumerate(outputs)]\n",
    "\n",
    "    self._final_state = state\n",
    "\n",
    "    # These are used both for pretraining and for D/G training further down.\n",
    "    self._lr = tf.Variable(FLAGS.learning_rate, trainable=False, dtype=data_type())\n",
    "    self.g_params = [v for v in tf.trainable_variables() if v.name.startswith('model/G/')]\n",
    "    if FLAGS.adam:\n",
    "      g_optimizer = tf.train.AdamOptimizer(self._lr)\n",
    "    else:\n",
    "      g_optimizer = tf.train.GradientDescentOptimizer(self._lr)\n",
    "   \n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    reg_constant = 0.1  # Choose an appropriate one.\n",
    "    reg_loss = reg_constant * sum(reg_losses)\n",
    "    reg_loss = tf.Print(reg_loss, reg_losses,\n",
    "                  'reg_losses = ', summarize=20, first_n=20)\n",
    "    #if not FLAGS.disable_l2_regularizer:\n",
    "    #  print('L2 regularization. Reg losses: {}'.format([v.name for v in reg_losses]))\n",
    "   \n",
    "    # ---BEGIN, PRETRAINING. ---\n",
    "    \n",
    "    print(tf.transpose(tf.stack(self._generated_features_pretraining), perm=[1, 0, 2]).get_shape())\n",
    "    print(self._input_songdata.get_shape())\n",
    "    self.rnn_pretraining_loss = tf.reduce_mean(tf.squared_difference(x=tf.transpose(tf.stack(self._generated_features_pretraining), perm=[1, 0, 2]), y=self._input_songdata))\n",
    "    if not FLAGS.disable_l2_regularizer:\n",
    "      self.rnn_pretraining_loss = self.rnn_pretraining_loss+reg_loss\n",
    "    \n",
    "    \n",
    "    pretraining_grads, _ = tf.clip_by_global_norm(tf.gradients(self.rnn_pretraining_loss, self.g_params), FLAGS.max_grad_norm)\n",
    "    self.opt_pretraining = g_optimizer.apply_gradients(zip(pretraining_grads, self.g_params))\n",
    "\n",
    "    # ---END, PRETRAINING---\n",
    "\n",
    "    # The discriminator tries to tell the difference between samples from the\n",
    "    # true data distribution (self.x) and the generated samples (self.z).\n",
    "    #\n",
    "    # Here we create two copies of the discriminator network (that share parameters),\n",
    "    # as you cannot use the same network with different inputs in TensorFlow.\n",
    "    with tf.variable_scope('D') as scope:\n",
    "      scope.set_regularizer(tf.contrib.layers.l2_regularizer(scale=FLAGS.reg_scale))\n",
    "      # Make list of tensors. One per step in recurrence.\n",
    "      # Each tensor is batchsize*numfeatures.\n",
    "      # TODO: (possibly temporarily) disabling meta info\n",
    "      print('self._input_songdata shape {}'.format(self._input_songdata.get_shape()))\n",
    "      print('generated data shape {}'.format(self._generated_features[0].get_shape()))\n",
    "      # TODO: (possibly temporarily) disabling meta info\n",
    "      if FLAGS.generate_meta:\n",
    "        songdata_inputs = [tf.concat([self._input_metadata, songdata_input],1) for songdata_input in songdata_inputs]\n",
    "      #print(songdata_inputs[0])\n",
    "      #print(songdata_inputs[0])\n",
    "      #print('metadata inputs shape {}'.format(self._input_metadata.get_shape()))\n",
    "      #print('generated metadata shape {}'.format(meta_probs.get_shape()))\n",
    "      self.real_d,self.real_d_features = self.discriminator(songdata_inputs, is_training, msg='real')\n",
    "      scope.reuse_variables()\n",
    "      # TODO: (possibly temporarily) disabling meta info\n",
    "      if FLAGS.generate_meta:\n",
    "        generated_data = [tf.concat([meta_probs, songdata_input],1) for songdata_input in self._generated_features]\n",
    "      else:\n",
    "        generated_data = self._generated_features\n",
    "      if songdata_inputs[0].get_shape() != generated_data[0].get_shape():\n",
    "        print('songdata_inputs shape {} != generated data shape {}'.format(songdata_inputs[0].get_shape(), generated_data[0].get_shape()))\n",
    "      self.generated_d,self.generated_d_features = self.discriminator(generated_data, is_training, msg='generated')\n",
    "\n",
    "    # Define the loss for discriminator and generator networks (see the original\n",
    "    # paper for details), and create optimizers for both\n",
    "    self.d_loss = tf.reduce_mean(-tf.log(tf.clip_by_value(self.real_d, 1e-1000000, 1.0)) \\\n",
    "                                 -tf.log(1 - tf.clip_by_value(self.generated_d, 0.0, 1.0-1e-1000000)))\n",
    "    self.g_loss_feature_matching = tf.reduce_sum(tf.squared_difference(self.real_d_features, self.generated_d_features))\n",
    "    self.g_loss = tf.reduce_mean(-tf.log(tf.clip_by_value(self.generated_d, 1e-1000000, 1.0)))\n",
    "\n",
    "    if not FLAGS.disable_l2_regularizer:\n",
    "      self.d_loss = self.d_loss+reg_loss\n",
    "      self.g_loss_feature_matching = self.g_loss_feature_matching+reg_loss\n",
    "      self.g_loss = self.g_loss+reg_loss\n",
    "    self.d_params = [v for v in tf.trainable_variables() if v.name.startswith('model/D/')]\n",
    "\n",
    "    if not is_training:\n",
    "      return\n",
    "\n",
    "    d_optimizer = tf.train.GradientDescentOptimizer(self._lr*FLAGS.d_lr_factor)\n",
    "    d_grads, _ = tf.clip_by_global_norm(tf.gradients(self.d_loss, self.d_params),\n",
    "                                        FLAGS.max_grad_norm)\n",
    "    self.opt_d = d_optimizer.apply_gradients(zip(d_grads, self.d_params))\n",
    "    if FLAGS.feature_matching:\n",
    "      g_grads, _ = tf.clip_by_global_norm(tf.gradients(self.g_loss_feature_matching,\n",
    "                                                       self.g_params),\n",
    "                                        FLAGS.max_grad_norm)\n",
    "    else:\n",
    "      g_grads, _ = tf.clip_by_global_norm(tf.gradients(self.g_loss, self.g_params),\n",
    "                                        FLAGS.max_grad_norm)\n",
    "    self.opt_g = g_optimizer.apply_gradients(zip(g_grads, self.g_params))\n",
    "\n",
    "    self._new_lr = tf.placeholder(shape=[], name=\"new_learning_rate\", dtype=data_type())\n",
    "    self._lr_update = tf.assign(self._lr, self._new_lr)\n",
    "\n",
    "  def discriminator(self, inputs, is_training, msg=''):\n",
    "    # RNN discriminator:\n",
    "    #for i in xrange(len(inputs)):\n",
    "    #  print('shape inputs[{}] {}'.format(i, inputs[i].get_shape()))\n",
    "    #inputs[0] = tf.Print(inputs[0], [inputs[0]],\n",
    "    #        '{} inputs[0] = '.format(msg), summarize=20, first_n=20)\n",
    "    if is_training and FLAGS.keep_prob < 1:\n",
    "      inputs = [tf.nn.dropout(input_, FLAGS.keep_prob) for input_ in inputs]\n",
    "    \n",
    "    #lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(FLAGS.hidden_size_d, forget_bias=1.0, state_is_tuple=True)\n",
    "    if is_training and FLAGS.keep_prob < 1:\n",
    "      #lstm_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "      #lstm_cell, output_keep_prob=FLAGS.keep_prob)\n",
    "      cell_fw = make_rnn_cell([FLAGS.hidden_size_d]* FLAGS.num_layers_d,dropout_keep_prob=FLAGS.keep_prob)\n",
    "      \n",
    "      cell_bw = make_rnn_cell([FLAGS.hidden_size_d]* FLAGS.num_layers_d,dropout_keep_prob=FLAGS.keep_prob)\n",
    "    else:\n",
    "      cell_fw = make_rnn_cell([FLAGS.hidden_size_d]* FLAGS.num_layers_d)\n",
    "      \n",
    "      cell_bw = make_rnn_cell([FLAGS.hidden_size_d]* FLAGS.num_layers_d)\n",
    "    #cell_fw = tf.nn.rnn_cell.MultiRNNCell([lstm_cell for _ in range( FLAGS.num_layers_d)], state_is_tuple=True)\n",
    "    self._initial_state_fw = cell_fw.zero_state(self.batch_size, data_type())\n",
    "    if not FLAGS.unidirectional_d:\n",
    "      self._initial_state_bw = cell_bw.zero_state(self.batch_size, data_type())\n",
    "      print(\"cell_fw\",cell_fw.output_size)\n",
    "      outputs, state_fw, state_bw = tf.contrib.rnn.static_bidirectional_rnn(cell_fw, cell_bw, inputs, initial_state_fw=self._initial_state_fw, initial_state_bw=self._initial_state_bw)\n",
    "    else:\n",
    "      outputs, state = tf.nn.rnn(cell_fw, inputs, initial_state=self._initial_state_fw)\n",
    "\n",
    "\n",
    "    if FLAGS.minibatch_d:\n",
    "      outputs = [minibatch(tf.reshape(outp, shape=[FLAGS.batch_size, -1]), msg=msg, reuse_scope=(i!=0)) for i,outp in enumerate(outputs)]\n",
    "    # decision = tf.sigmoid(linear(outputs[-1], 1, 'decision'))\n",
    "    if FLAGS.end_classification:\n",
    "      decisions = [tf.sigmoid(linear(output, 1, 'decision', reuse_scope=(i!=0))) for i,output in enumerate([outputs[0], outputs[-1]])]\n",
    "      decisions = tf.stack(decisions)\n",
    "      decisions = tf.transpose(decisions, perm=[1,0,2])\n",
    "      print('shape, decisions: {}'.format(decisions.get_shape()))\n",
    "    else:\n",
    "      decisions = [tf.sigmoid(linear(output, 1, 'decision', reuse_scope=(i!=0))) for i,output in enumerate(outputs)]\n",
    "      decisions = tf.stack(decisions)\n",
    "      decisions = tf.transpose(decisions, perm=[1,0,2])\n",
    "      print('shape, decisions: {}'.format(decisions.get_shape()))\n",
    "    decision = tf.reduce_mean(decisions, reduction_indices=[1,2])\n",
    "    decision = tf.Print(decision, [decision],\n",
    "            '{} decision = '.format(msg), summarize=20, first_n=20)\n",
    "    return (decision,tf.transpose(tf.stack(outputs), perm=[1,0,2]))\n",
    "  \n",
    "  def assign_lr(self, session, lr_value):\n",
    "    session.run(self._lr_update, feed_dict={self._new_lr: lr_value})\n",
    "\n",
    "  @property\n",
    "  def generated_features(self):\n",
    "    return self._generated_features\n",
    "\n",
    "  @property\n",
    "  def input_songdata(self):\n",
    "    return self._input_songdata\n",
    "\n",
    "  @property\n",
    "  def input_metadata(self):\n",
    "    return self._input_metadata\n",
    "\n",
    "  @property\n",
    "  def targets(self):\n",
    "    return self._targets\n",
    "\n",
    "  @property\n",
    "  def initial_state(self):\n",
    "    return self._initial_state\n",
    "\n",
    "  @property\n",
    "  def cost(self):\n",
    "    return self._cost\n",
    "\n",
    "  @property\n",
    "  def final_state(self):\n",
    "    return self._final_state\n",
    "\n",
    "  @property\n",
    "  def lr(self):\n",
    "    return self._lr\n",
    "\n",
    "  @property\n",
    "  def train_op(self):\n",
    "    return self._train_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(session, model, loader, datasetlabel, eval_op_g, eval_op_d, pretraining=False, verbose=False, run_metadata=None, pretraining_d=False):\n",
    "  \"\"\"Runs the model on the given data.\"\"\"\n",
    "  #epoch_size = ((len(data) // model.batch_size) - 1) // model.songlength\n",
    "  epoch_start_time = time.time()\n",
    "  g_loss, d_loss = 10.0, 10.0\n",
    "  g_losses, d_losses = 0.0, 0.0\n",
    "  iters = 0\n",
    "  #state = session.run(model.initial_state)\n",
    "  time_before_graph = None\n",
    "  time_after_graph = None\n",
    "  times_in_graph = []\n",
    "  times_in_python = []\n",
    "  #times_in_batchreading = []\n",
    "  loader.rewind(part=datasetlabel)\n",
    "  [batch_meta, batch_song] = loader.get_batch(model.batch_size, model.songlength, part=datasetlabel)\n",
    "\n",
    "  run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "\n",
    "  while batch_meta is not None and batch_song is not None:\n",
    "    op_g = eval_op_g\n",
    "    op_d = eval_op_d\n",
    "    if datasetlabel == 'train' and not pretraining: # and not FLAGS.feature_matching:\n",
    "      if d_loss == 0.0 and g_loss == 0.0:\n",
    "        print('Both G and D train loss are zero. Exiting.')\n",
    "        break\n",
    "        #saver.save(session, checkpoint_path, global_step=m.global_step)\n",
    "        #break\n",
    "      elif d_loss == 0.0:\n",
    "        #print('D train loss is zero. Freezing optimization. G loss: {:.3f}'.format(g_loss))\n",
    "        op_g = tf.no_op()\n",
    "      elif g_loss == 0.0: \n",
    "        #print('G train loss is zero. Freezing optimization. D loss: {:.3f}'.format(d_loss))\n",
    "        op_d = tf.no_op()\n",
    "      elif g_loss < 2.0 or d_loss < 2.0:\n",
    "        if g_loss*.7 > d_loss:\n",
    "          #print('G train loss is {:.3f}, D train loss is {:.3f}. Freezing optimization of D'.format(g_loss, d_loss))\n",
    "          op_g = tf.no_op()\n",
    "        #elif d_loss*.7 > g_loss:\n",
    "          #print('G train loss is {:.3f}, D train loss is {:.3f}. Freezing optimization of G'.format(g_loss, d_loss))\n",
    "        op_d = tf.no_op()\n",
    "    #fetches = [model.cost, model.final_state, eval_op]\n",
    "    if pretraining:\n",
    "      if pretraining_d:\n",
    "        fetches = [model.rnn_pretraining_loss, model.d_loss, op_g, op_d]\n",
    "      else:\n",
    "        fetches = [model.rnn_pretraining_loss, tf.no_op(), op_g, op_d]\n",
    "    else:\n",
    "      fetches = [model.g_loss, model.d_loss, op_g, op_d]\n",
    "    feed_dict = {}\n",
    "    feed_dict[model.input_songdata.name] = batch_song\n",
    "    feed_dict[model.input_metadata.name] = batch_meta\n",
    "    #print(batch_song)\n",
    "    #print(batch_song.shape)\n",
    "    \n",
    "    #for i, (c, h) in enumerate(model.initial_state):\n",
    "    #  feed_dict[c] = state[i].c\n",
    "    #  feed_dict[h] = state[i].h\n",
    "    #cost, state, _ = session.run(fetches, feed_dict)\n",
    "    time_before_graph = time.time()\n",
    "    if iters > 0:\n",
    "      times_in_python.append(time_before_graph-time_after_graph)\n",
    "    if run_metadata:\n",
    "      g_loss, d_loss, _, _ = session.run(fetches, feed_dict, options=run_options, run_metadata=run_metadata)\n",
    "    else:\n",
    "      g_loss, d_loss, _, _ = session.run(fetches, feed_dict)\n",
    "    time_after_graph = time.time()\n",
    "    if iters > 0:\n",
    "      times_in_graph.append(time_after_graph-time_before_graph)\n",
    "    g_losses += g_loss\n",
    "    if not pretraining:\n",
    "      d_losses += d_loss\n",
    "    iters += 1\n",
    "\n",
    "    if verbose and iters % 10 == 9:\n",
    "      songs_per_sec = float(iters * model.batch_size)/float(time.time() - epoch_start_time)\n",
    "      avg_time_in_graph = float(sum(times_in_graph))/float(len(times_in_graph))\n",
    "      avg_time_in_python = float(sum(times_in_python))/float(len(times_in_python))\n",
    "      #avg_time_batchreading = float(sum(times_in_batchreading))/float(len(times_in_batchreading))\n",
    "      if pretraining:\n",
    "        print(\"{}: {} (pretraining) batch loss: G: {:.3f}, avg loss: G: {:.3f}, speed: {:.1f} songs/s, avg in graph: {:.1f}, avg in python: {:.1f}.\".format(datasetlabel, iters, g_loss, float(g_losses)/float(iters), songs_per_sec, avg_time_in_graph, avg_time_in_python))\n",
    "      else:\n",
    "        print(\"{}: {} batch loss: G: {:.3f}, D: {:.3f}, avg loss: G: {:.3f}, D: {:.3f} speed: {:.1f} songs/s, avg in graph: {:.1f}, avg in python: {:.1f}.\".format(datasetlabel, iters, g_loss, d_loss, float(g_losses)/float(iters), float(d_losses)/float(iters),songs_per_sec, avg_time_in_graph, avg_time_in_python))\n",
    "    #batchtime = time.time()\n",
    "    [batch_meta, batch_song] = loader.get_batch(model.batch_size, model.songlength, part=datasetlabel)\n",
    "    #times_in_batchreading.append(time.time()-batchtime)\n",
    "\n",
    "  if iters == 0:\n",
    "    return (None,None)\n",
    "\n",
    "  g_mean_loss = g_losses/iters\n",
    "  if pretraining and not pretraining_d:\n",
    "    d_mean_loss = None\n",
    "  else:\n",
    "    d_mean_loss = d_losses/iters\n",
    "  return (g_mean_loss, d_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(session, model, batch=False):\n",
    "  \"\"\"Samples from the generative model.\"\"\"\n",
    "  #state = session.run(model.initial_state)\n",
    "  fetches = [model.generated_features]\n",
    "  feed_dict = {}\n",
    "  generated_features, = session.run(fetches, feed_dict)\n",
    "  #print( generated_features)\n",
    "  print( generated_features[0].shape)\n",
    "  # The following worked when batch_size=1.\n",
    "  # generated_features = [np.squeeze(x, axis=0) for x in generated_features]\n",
    "  # If batch_size != 1, we just pick the first sample. Wastefull, yes.\n",
    "  returnable = []\n",
    "  if batch:\n",
    "    for batchno in range(generated_features[0].shape[0]):\n",
    "      returnable.append([x[batchno,:] for x in generated_features])\n",
    "  else:\n",
    "    returnable = [x[0,:] for x in generated_features]\n",
    "  return returnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.datadir = \"data/\"#datadir to midi music dir\n",
    "FLAGS.traindir = \"traindir/\"#dir where I can save model and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-21 17:34:50: saved_args: disable_feed_previous from saved state (False), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: num_layers_g from saved state (2), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: num_layers_d from saved state (2), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: meta_layer_size from saved state (200), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: hidden_size_g from saved state (100), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: hidden_size_d from saved state (100), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: biscale_slow_layer_ticks from saved state (8), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: multiscale from saved state (False), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: pace_events from saved state (False), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: minibatch_d from saved state (False), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: unidirectional_d from saved state (False), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: feature_matching from saved state (False), ignoring CLI args.\n",
      "2020-07-21 17:34:50: saved_args: composer from saved state (None), ignoring CLI args.\n"
     ]
    }
   ],
   "source": [
    "#新建traindir/saved_args ，并保存参数\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')#解决在jupyter中会存在下载cifar10的问题\n",
    "restore_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新建traindir/summaries、traindir/plots、traindir/generated_data 三个目录\n",
    "summaries_dir = os.path.join(FLAGS.traindir, 'summaries')\n",
    "plots_dir = os.path.join(FLAGS.traindir, 'plots')\n",
    "generated_data_dir = os.path.join(FLAGS.traindir, 'generated_data')\n",
    "try: os.makedirs(FLAGS.traindir)\n",
    "except: pass\n",
    "try: os.makedirs(summaries_dir)\n",
    "except: pass\n",
    "try: os.makedirs(plots_dir)\n",
    "except: pass\n",
    "try: os.makedirs(generated_data_dir)\n",
    "except: pass\n",
    "directorynames = FLAGS.traindir.split('/')\n",
    "experiment_label = ''\n",
    "while not experiment_label:\n",
    "    experiment_label = directorynames.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = -1\n",
    "if os.path.exists(os.path.join(FLAGS.traindir, 'global_step.pkl')): #不执行的代码\n",
    "    print(\"hello\")\n",
    "    with open(os.path.join(FLAGS.traindir, 'global_step.pkl'), 'r') as f:\n",
    "      global_step = pkl.load(f)\n",
    "global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不执行的代码\n",
    "synthetic=None\n",
    "if FLAGS.synthetic_chords:#不执行的代码\n",
    "    synthetic = 'chords'\n",
    "    print('Training on synthetic chords!')#译：在合成和弦上训练\n",
    "if FLAGS.composer is not None:#不执行的代码\n",
    "    print('Single composer: {}'.format(FLAGS.composer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader: datadir: data/\n",
      "midi data\n",
      "Already completely downloaded, delete do-not-redownload.txt to check for files to download.\n",
      "num genres:1\n",
      "num composers: 154\n",
      "limit works per composer: None\n",
      "Reading files classical/adam: 3\n",
      "Reading files classical/aguado: 5\n",
      "Reading files classical/albenizisaac: 20\n",
      "Reading files classical/albenizmateo: 2\n",
      "Reading files classical/albinoni: 1\n",
      "Reading files classical/alford: 2\n",
      "Reading files classical/alkan: 11\n",
      "Reading files classical/anderson: 8\n",
      "Reading files classical/ansell: 1\n",
      "Reading files classical/arensky: 5\n",
      "Reading files classical/arriaga: 2\n",
      "Reading files classical/bach: 100\n",
      "Reading files classical/bach: 200\n",
      "Reading files classical/bach: 300\n",
      "Reading files classical/bach: 360\n",
      "Reading files classical/barber: 8\n",
      "Path does not exist: data/classical\\barbieri\n",
      "Reading files classical/bartok: 99\n",
      "Reading files classical/bax: 2\n",
      "Error reading data/classical\\beethoven\\14715thSympnmov1.mid\n",
      "Reading files classical/beethoven: 68\n",
      "Reading files classical/bellini: 4\n",
      "Reading files classical/bergmuller: 48\n",
      "Reading files classical/berlin: 3\n",
      "Reading files classical/berlioz: 3\n",
      "Reading files classical/binge: 3\n",
      "Reading files classical/bizet: 17\n",
      "Path does not exist: data/classical\\boccherini\n",
      "Path does not exist: data/classical\\boellman\n",
      "Reading files classical/borodin: 4\n",
      "Reading files classical/bouwer: 2\n",
      "Reading files classical/boyce: 3\n",
      "Reading files classical/brahms: 62\n",
      "Reading files classical/breton: 2\n",
      "Reading files classical/britten: 9\n",
      "Reading files classical/bruch: 1\n",
      "Reading files classical/bruckner: 1\n",
      "Reading files classical/busoni: 2\n",
      "Reading files classical/byrd: 100\n",
      "Reading files classical/byrd: 118\n",
      "Reading files classical/carulli: 5\n",
      "Reading files classical/chabrier: 3\n",
      "Reading files classical/chaminade: 12\n",
      "Reading files classical/chapi: 2\n",
      "Path does not exist: data/classical\\cherubini\n",
      "Reading files classical/chopin: 100\n",
      "Reading files classical/chopin: 143\n",
      "Path does not exist: data/classical\\clementi\n",
      "Reading files classical/coates: 9\n",
      "Error reading data/classical\\copland\\898promise2.mid\n",
      "Reading files classical/copland: 5\n",
      "Reading files classical/corelli: 24\n",
      "Reading files classical/cramer: 14\n",
      "Path does not exist: data/classical\\curzon\n",
      "Reading files classical/czerny: 24\n",
      "Reading files classical/debussy: 23\n",
      "Path does not exist: data/classical\\delibes\n",
      "Reading files classical/delius: 8\n",
      "Path does not exist: data/classical\\dialoc\n",
      "Reading files classical/dupre: 12\n",
      "Reading files classical/dussek: 3\n",
      "Path does not exist: data/classical\\dvorak\n",
      "Reading files classical/elgar: 8\n",
      "Reading files classical/eshpai: 2\n",
      "Reading files classical/faure: 16\n",
      "Reading files classical/field: 4\n",
      "Reading files classical/flotow: 2\n",
      "Reading files classical/foster: 5\n",
      "Reading files classical/franck: 7\n",
      "Path does not exist: data/classical\\fresc\n",
      "Reading files classical/garoto: 1\n",
      "Reading files classical/german: 30\n",
      "Error reading data/classical\\gershwin\\2221americanparis.mid\n",
      "Error reading data/classical\\gershwin\\2420gglullaby.mid\n",
      "Error reading data/classical\\gershwin\\2678necessar.mid\n",
      "Error reading data/classical\\gershwin\\GershwinPC1.mid\n",
      "Error reading data/classical\\gershwin\\GershwinPC2.mid\n",
      "Reading files classical/gershwin: 14\n",
      "Error reading data/classical\\gershwin\\GershwinPC3.mid\n",
      "Reading files classical/gilbert: 5\n",
      "Path does not exist: data/classical\\ginast\n",
      "Path does not exist: data/classical\\gott\n",
      "Reading files classical/gounod: 16\n",
      "Path does not exist: data/classical\\grain\n",
      "Error reading data/classical\\grieg\\1857dehalvandebergkoning.mid\n",
      "Reading files classical/grieg: 24\n",
      "Path does not exist: data/classical\\griff\n",
      "Reading files classical/handel: 100\n",
      "Reading files classical/handel: 200\n",
      "Reading files classical/handel: 293\n",
      "Reading files classical/haydn: 67\n",
      "Reading files classical/heller: 24\n",
      "Reading files classical/herold: 1\n",
      "Reading files classical/hiller: 2\n",
      "Error reading data/classical\\holst\\845danceSteven.mid\n",
      "Reading files classical/holst: 23\n",
      "Reading files classical/hummel: 100\n",
      "Reading files classical/hummel: 137\n",
      "Reading files classical/ibert: 3\n",
      "Reading files classical/ives: 3\n",
      "Reading files classical/janacek: 6\n",
      "Reading files classical/joplin: 10\n",
      "Reading files classical/jstrauss: 5\n",
      "Path does not exist: data/classical\\karg\n",
      "Path does not exist: data/classical\\khach\n",
      "Reading files classical/kuhlau: 8\n",
      "Path does not exist: data/classical\\lalo\n",
      "Reading files classical/lemire: 19\n",
      "Reading files classical/lenar: 4\n",
      "Reading files classical/liszt: 45\n",
      "Reading files classical/lobos: 20\n",
      "Path does not exist: data/classical\\lovland\n",
      "Path does not exist: data/classical\\lyssen\n",
      "Path does not exist: data/classical\\maccunn\n",
      "Reading files classical/mahler: 6\n",
      "Error reading data/classical\\maier\\atala15.mid\n",
      "Error reading data/classical\\maier\\atala21.mid\n",
      "Error reading data/classical\\maier\\atala32.mid\n",
      "Error reading data/classical\\maier\\atalan1.mid\n",
      "Error reading data/classical\\maier\\atalan2.mid\n",
      "Reading files classical/maier: 52\n",
      "Reading files classical/marcello: 4\n",
      "Reading files classical/martini: 3\n",
      "Reading files classical/mehul: 2\n",
      "Reading files classical/mendelssohn: 55\n",
      "Reading files classical/messager: 24\n",
      "Path does not exist: data/classical\\messia\n",
      "Reading files classical/meyerbeer: 3\n",
      "Path does not exist: data/classical\\modest\n",
      "Path does not exist: data/classical\\moszkowski\n",
      "Reading files classical/mozart: 100\n",
      "Reading files classical/mozart: 133\n",
      "Reading files classical/nikolaievich: 31\n",
      "Reading files classical/orff: 3\n",
      "Reading files classical/pachelbel: 73\n",
      "Reading files classical/paderewski: 1\n",
      "Path does not exist: data/classical\\pagg\n",
      "Reading files classical/palestrina: 11\n",
      "Reading files classical/paradisi: 2\n",
      "Reading files classical/poulenc: 17\n",
      "Reading files classical/pres: 5\n",
      "Path does not exist: data/classical\\prokif\n",
      "Reading files classical/puccini: 14\n",
      "Reading files classical/rachmaninov: 100\n",
      "Reading files classical/rachmaninov: 102\n",
      "Reading files classical/ravel: 18\n",
      "Path does not exist: data/classical\\respig\n",
      "Reading files classical/rimsky: 11\n",
      "Reading files classical/rossini: 12\n",
      "Reading files classical/sacrlatt: 7\n",
      "Path does not exist: data/classical\\saens\n",
      "Reading files classical/sanz: 10\n",
      "Reading files classical/satie: 26\n",
      "Reading files classical/scarlatti: 7\n",
      "Reading files classical/schoberg: 2\n",
      "Reading files classical/schubert: 27\n",
      "Reading files classical/schumann: 54\n",
      "Reading files classical/scriabin: 24\n",
      "Reading files classical/shostakovich: 22\n",
      "Reading files classical/sibelius: 18\n",
      "Reading files classical/soler: 18\n",
      "Reading files classical/sor: 24\n",
      "Reading files classical/sousa: 11\n",
      "Reading files classical/strauss: 4\n",
      "Reading files classical/stravinsky: 32\n",
      "Reading files classical/sullivan: 57\n",
      "Reading files classical/susato: 1\n",
      "Reading files classical/taktak: 2\n",
      "Reading files classical/taylor: 4\n",
      "Reading files classical/tchaikovsky: 50\n",
      "Reading files classical/thomas: 3\n",
      "Reading files classical/vaughan: 16\n",
      "Reading files classical/verdi: 16\n",
      "Reading files classical/vivaldi: 23\n",
      "Reading files classical/wagner: 9\n",
      "Reading files classical/walton: 5\n",
      "Reading files classical/wolf: 2\n",
      "Reading files classical/wyschnegradsky: 2\n",
      "Reading files classical/yradier: 1\n"
     ]
    }
   ],
   "source": [
    "#加载data/classical下的文件\n",
    "loader = music_data_utils.MusicDataLoader(FLAGS.datadir, FLAGS.select_validation_percentage, FLAGS.select_test_percentage, FLAGS.works_per_composer, FLAGS.pace_events, synthetic=synthetic, tones_per_cell=FLAGS.tones_per_cell, single_composer=FLAGS.composer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不执行的代码\n",
    "if FLAGS.synthetic_chords:\n",
    "# This is just a print out, to check the generated data.\n",
    "    print(\"hello\")\n",
    "    batch = loader.get_batch(batchsize=1, songlength=400)\n",
    "    loader.get_midi_pattern([batch[1][0][i] for i in xrange(batch[1].shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_song_features:4\n",
      "num_meta_features:155\n"
     ]
    }
   ],
   "source": [
    "#在loader读出num_song_features、num_meta_features\n",
    "num_song_features = loader.get_num_song_features()\n",
    "print('num_song_features:{}'.format(num_song_features))\n",
    "num_meta_features = loader.get_num_meta_features()\n",
    "print('num_meta_features:{}'.format(num_meta_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练开始计时\n",
    "train_start_time = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型输出路径 设为traindir/model.ckpt\n",
    "checkpoint_path = os.path.join(FLAGS.traindir, \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "songlength_ceiling = FLAGS.songlength\n",
    "songlength_ceiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if global_step < FLAGS.pretraining_epochs:\n",
    "    FLAGS.songlength = int(min(((global_step+10)/10)*10,songlength_ceiling))\n",
    "    FLAGS.songlength = int(min((global_step+1)*4,songlength_ceiling))\n",
    "FLAGS.songlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Graph.as_default of <tensorflow.python.framework.ops.Graph object at 0x0000020B191E9F98>>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建默认的计算图\n",
    "myGraph = tf.Graph()\n",
    "myGraph.as_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在myGraph中创建一个会话\n",
    "session = tf.Session(graph=myGraph,config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "songlength: 4\n",
      "self._input_songdata Tensor(\"model/Placeholder:0\", shape=(20, 4, 4), dtype=float32) songlength 4\n",
      "(20, 4, 4)\n",
      "(20, 4, 4)\n",
      "self._input_songdata shape (20, 4, 4)\n",
      "generated data shape (20, 4)\n",
      "cell_fw 100\n",
      "shape, decisions: (20, 4, 1)\n",
      "cell_fw 100\n",
      "shape, decisions: (20, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "#创建网络\n",
    "with tf.variable_scope(\"model\", reuse=None) as scope:\n",
    "    scope.set_regularizer(tf.contrib.layers.l2_regularizer(scale=FLAGS.reg_scale))\n",
    "    m = RNNGAN(is_training=True, num_song_features=num_song_features, num_meta_features=num_meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不执行的代码\n",
    "if FLAGS.initialize_d:\n",
    "  vars_to_restore = {}\n",
    "  for v in tf.trainable_variables():\n",
    "    if v.name.startswith('model/G/'):\n",
    "      print(v.name[:-2])\n",
    "      vars_to_restore[v.name[:-2]] = v\n",
    "  saver = tf.train.Saver(vars_to_restore)\n",
    "  ckpt = tf.train.get_checkpoint_state(FLAGS.traindir)\n",
    "  if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n",
    "    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path,end=\" \")\n",
    "    saver.restore(session, ckpt.model_checkpoint_path)\n",
    "    session.run(tf.initialize_variables([v for v in tf.trainable_variables() if v.name.startswith('model/D/')]))\n",
    "  else:\n",
    "    print(\"Created model with fresh parameters.\")\n",
    "    session.run(tf.initialize_all_variables())\n",
    "  saver = tf.train.Saver(tf.all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-3ecbdbdf255e>:1: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "Created model with fresh parameters.\n",
      "WARNING:tensorflow:From D:\\APP_Home\\Anaconda\\envs\\brats_tf\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty.  Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-3ecbdbdf255e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Created model with fresh parameters.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\APP_Home\\Anaconda\\envs\\brats_tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\APP_Home\\Anaconda\\envs\\brats_tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1058\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempted to use a closed Session.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[0;32m   1061\u001b[0m                          'graph before calling run().')\n\u001b[0;32m   1062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.all_variables())#tf.train.Saver() 保存和加载模型\n",
    "ckpt = tf.train.get_checkpoint_state(FLAGS.traindir)#通过checkpoint文件找到模型文件名\n",
    "#如果有训练好的模型，就加载它\n",
    "if ckpt and tf.gfile.Exists(ckpt.model_checkpoint_path):\n",
    "    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n",
    "    saver.restore(session, ckpt.model_checkpoint_path)\n",
    "#否则，运行会话\n",
    "else:\n",
    "    print(\"Created model with fresh parameters.\")\n",
    "    session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#关闭当前会话\n",
    "#session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
